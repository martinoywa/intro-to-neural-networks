{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b01bad-13ba-46fe-a00b-a752e9f9d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b2368-7764-41b6-9568-7f9f1b25023b",
   "metadata": {},
   "source": [
    "- Neural Networks (NNs) form the backbone of modern AI through Deep Learning.\n",
    "- They are a network of interconnected nodes that can learn from data, make predictions, and uncover complex patterns in the most diverse datasets inspired by the human brain.\n",
    "\n",
    "![Insert Image of Neural Network](images/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork.png)\n",
    "\n",
    "- Use cases for these networks and algorithms include; Image Classification (CNNs), Text Classification (BERT, RNNs), Image Segmentation (CNNs), Text Generation (GPTs), Image Generation (GANs)\n",
    "\n",
    "\n",
    "Links;\n",
    "\n",
    "1. Text Classification. https://www.analyticsvidhya.com/blog/2020/12/understanding-text-classification-in-nlp-with-movie-review-example-example/\n",
    "2. Image Segmentation. https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/\n",
    "3. Text Generation. https://openai.com/blog/chatgpt\n",
    "4. Image Generation. https://openai.com/dall-e-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7dc81-f040-4d9f-aec3-06f7f6162dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3ad59-c756-4d6c-89b8-651e1df918cf",
   "metadata": {},
   "source": [
    "- NNs are comprised of node layers (an input layer, one or more hidden layers, and an output layer).\n",
    "- Each node has an associated weight and bias/threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\n",
    "- Weights determine the importance of its input value, the larger the assigned weight, the more important the value is.\n",
    "\n",
    "![Insert Image of Perceptron](images/0_LJBO8UbtzK_SKMog.png)\n",
    "\n",
    "Think of it as the linear equation; $y = Wx + b$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d027ef-acec-4d7c-8b3f-71ef73f89139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Fuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccae060-8e00-4c72-b781-86c32e8c98a8",
   "metadata": {},
   "source": [
    "- Some key functions used to help NNs include; Activation Functions, Cost Functions and Optimization Functions\n",
    "- Activation functions help NNs learn non-Linear decision boundaries, i.e the complex in complex data. Some such as Sigmoid and Softmax can be used in output layers to determine the kind of task you're doing, binary classification or multi-class classification resp.\n",
    "![Tanh Example](images/Screenshot%202023-10-20%20at%2011.10.25.png)\n",
    "  \n",
    "- Cost functions help in error/loss calculation, e.g MSE.\n",
    "- Optimization functions are responsible for the method by which your model weights or parameters will be updated, e.g SGD uses the negative gradient of the loss with respect to the data points. Basically how your model learns.\n",
    "\n",
    "![Gradient Descent](images/ICLH_Diagram_Batch_01_04-GradientDescent.png)\n",
    "\n",
    "\n",
    "Links;\n",
    "1. Activation Functions. https://github.com/DSC-Laikipia-University/MNIST-Classifier/blob/master/activation_functions.ipynb, https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity, https://pytorch.org/docs/stable/nn.html#non-linear-activations-other\n",
    "2. SGD. https://realpython.com/gradient-descent-algorithm-python/\n",
    "3. Cost Functions. https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098dfa0-409e-453c-9577-abd05aed0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do they work internally? Mathematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36510227-6b54-46e2-b2aa-492481981aaf",
   "metadata": {},
   "source": [
    "Starter function.\n",
    "$$\n",
    "y = \\sum W_ix_i + b\n",
    "$$\n",
    "\n",
    "\n",
    "Expand it.\n",
    "$$\n",
    "y=W_1⋅x_1 + W_2⋅x_2 + W_3⋅x_3 + b\n",
    "$$\n",
    "\n",
    "Our Activation Function.\n",
    "$$\n",
    "output = f(x) = 1 \\text{ if} \\sum W_ix_i + b>= 0 \\text{ ; } 0 \\text{ if} \\sum W_ix_i + b < 0\n",
    "$$\n",
    "\n",
    "Example: The above function represents a NN that is meant to determine whether you'll attend (y) an event, i.e. a binary decision of Yes. 1 and No. 2. This decision is influenced by the following three variables (1 - True, 0 - False in this case);\n",
    "1. Will there be swag (Stickers and such)? (Yes: 0, No: 1)\n",
    "2. Is the event within Nairobi? (Yes: 1, No: 0)\n",
    "3. Is the event about Machine Learning? (Yes: 1, No: 0)\n",
    "\n",
    "Let's assign our model input variables values based on the influences.\n",
    "$$\n",
    "x_1 = 0, \\text{since no swag}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_2 = 1, \\text{since event is within the City}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_3 = 1, \\text{since even is ML based}\n",
    "$$\n",
    "\n",
    "What about the weights? Weight initialization is normally random, so let's randomize.\n",
    "Note; you'll normally not need to do this in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada2a20b-6b99-4f31-bbdc-86eeab17803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy weight initialization\n",
    "import random\n",
    "\n",
    "def d_w_i():\n",
    "    W_1 = random.randint(0, 10)\n",
    "    W_2 = random.randint(0, 10)\n",
    "    W_3 = random.randint(0, 10)\n",
    "\n",
    "    return W_1, W_2, W_3\n",
    "    \n",
    "W_1, W_2, W_3 = d_w_i()\n",
    "W_1, W_2, W_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029d4e4-c2cb-45e6-94ba-4a0220a9b306",
   "metadata": {},
   "source": [
    "$$\n",
    "W_1 = 7,\n",
    "W_2 = 8,\n",
    "W_3 = 9,\n",
    "$$\n",
    "\n",
    "Let's set a bias value of -4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ec589e1-2bb8-4cf1-ae4e-7ae1bc447d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = W_1*0 + W_2*1 + W_3*1 - 4\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eecd64-6852-4d10-896d-dcb98321fec3",
   "metadata": {},
   "source": [
    "Since y > 0, according to our activation function, our prediction is YES/1, there, we'll attend the event.\n",
    "\n",
    "In this scenario will not include loss calculation but it's something that you can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bae3832-f60e-4a3f-8dcf-d184e5924be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematics fucntions -> Image Representation -> Python Code (Handwritten Digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44e562-1fa0-4b44-9361-c160e2eb8650",
   "metadata": {},
   "source": [
    "Let's now adapt this function to train a model that can classify MNIST handwritten digits. We only included the sigmoid function symbol.\n",
    "\n",
    "$$\n",
    "y = \\sigma(\\sum W_ix_i + b_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "y=σ(W3⋅(W2⋅(W1⋅x+b1)+b2)+b3)\n",
    "$$\n",
    "\n",
    "![Image of Network]\n",
    "\n",
    "Note:\n",
    "- We'll be using PyTorch.\n",
    "- Bias and Weights will automatically calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00ab4f-82d4-42df-bd11-a1dcc2df7787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756561e-6c1b-4b38-a131-df06078d25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18009d-7655-419c-a37e-756fb05fef27",
   "metadata": {},
   "source": [
    "- Training involves three major concepts; Forward Propagation, Error Calculation, and Back Propagation.\n",
    "- Forwards propagation is what we've been describing i.e. moving the input data through the network.\n",
    "- Error/Loss calculation, similar to basic ML, is determining how good your model is compared to your ground truth. Difference between you y_pred and y_test.\n",
    "- Back Propagation. This can be considered a crucial step as it determines how your model learns, i.e. updates the weights accordingly towards minimizing the loss during training. (A bunch of dy/dx calculations!)\n",
    "\n",
    "Resources of Back Propagation;\n",
    "1. https://en.wikipedia.org/wiki/Backpropagation\n",
    "2. https://brilliant.org/wiki/backpropagation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff239088-4df9-48e9-a504-23c7c5bdb4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be7af38-3729-4907-bdec-0dcf5a4aead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c53e8-d6be-4a3f-b894-50019d9e85ef",
   "metadata": {},
   "source": [
    "1. PyTorch Course NYU. https://github.com/Atcold/NYU-DLSP20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087e0ac-bca3-4110-85aa-4f540086f743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
